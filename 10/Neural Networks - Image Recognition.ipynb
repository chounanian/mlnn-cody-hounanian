{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks - Image Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 20:55:52.366284: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Neural Network\n",
    "Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9a37c57160>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.max(x_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n",
       "       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n",
       "       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n",
       "       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n",
       "       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509807,\n",
       "       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n",
       "       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n",
       "       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n",
       "       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n",
       "       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n",
       "       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n",
       "       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n",
       "       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9a351b9dc0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOxUlEQVR4nO3df6zV9X3H8deLK6CipqITGTJ1iloyI513aEezupgSaxahri6ypqOZkS7VTRfb1bkttcuyOdpqTWNNsNKiVbsm1spSs8qYm3WulKuliMUVS1ERxq2jKrWAXHjvj3tYbvV+P+dyfnPfz0dyc875vs/3ft8c7ut+zz2f7/f7cUQIwPg3odsNAOgMwg4kQdiBJAg7kARhB5I4opMbm+TJcaSmdHKTQCp79IbejL0erdZU2G1fIul2SX2SvhQRt5Sef6Sm6AJf3MwmARSsidWVtYbfxtvuk3SHpPdLmi1pke3ZjX4/AO3VzN/scyU9HxGbI+JNSV+TtKA1bQFotWbCPkPSSyMeb60t+yW2l9gesD2wT3ub2ByAZjQT9tE+BHjbsbcRsSwi+iOif6ImN7E5AM1oJuxbJc0c8fgUSduaawdAuzQT9rWSZtk+3fYkSVdKWtmatgC0WsNDbxExZPtaSd/W8NDb8oh4tmWdAWippsbZI+IRSY+0qBcAbcThskAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkmpqy2fYWSbsk7Zc0FBH9rWgKQOs1Ffaa342IV1rwfQC0EW/jgSSaDXtIetT2U7aXjPYE20tsD9ge2Ke9TW4OQKOafRs/LyK22T5J0irbz0XE4yOfEBHLJC2TpOM8NZrcHoAGNbVnj4httdtBSQ9JmtuKpgC0XsNhtz3F9rEH70uaL2lDqxoD0FrNvI2fJukh2we/z/0R8S8t6QpAyzUc9ojYLOm8FvYCoI0YegOSIOxAEoQdSIKwA0kQdiCJVpwIg8PYhDmzi/U9J08p1rcsdLH+wblrK2v7oq+47mP3lo/Rmv4frxXr8f1ni/Vs2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs48DMW9OZW3zNeV173/3XcX6+ZPKY+Ft9YnvFcu7P/5msb7s1epjCL74g/cW15111cZi/cCePcV6L2LPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM7eAw68Z06xvuVj5fW/Ne+OytoZRxxVZ+vlcfRVu8vr3/TDhcX6qy++o7K2YeEXiuv+zY4Li/WlJw8U6+cd9UJl7da5/1Rc9y///CPF+in/8GSx3ovYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEo6Ijm3sOE+NC3xxx7bXKzbfP6dYv6+N55Qv+sn7ivW1z51erJ9zXZ3zut9445B7Omjafx1XrA/+2anF+ll3Ples//W0f6+sfWf39OK6l035WbG+8MIFxfrQS1uL9XZZE6v1euwc9WL+dffstpfbHrS9YcSyqbZX2d5Uuz2+lQ0DaL2xvI3/iqRL3rLsRkmrI2KWpNW1xwB6WN2wR8Tjkna+ZfECSStq91dIWtjatgC0WqMf0E2LiO2SVLs9qeqJtpfYHrA9sE97G9wcgGa1/dP4iFgWEf0R0T9Rk9u9OQAVGg37DtvTJal2O9i6lgC0Q6NhXylpce3+YkkPt6YdAO1S93x22w9IukjSiba3SvqUpFskfd32VZJelHRFO5vsBROmVM9Tvulvzy2uu/G91eebS9KEOueUr91bPhbiQw9XXxz+7E+Xx8nPerV8TviBYrU55x77crG+6ojyMQADnzm/WD/h1jWVtYVTXi2uK5XnnT8c1Q17RCyqKOU7OgY4jHG4LJAEYQeSIOxAEoQdSIKwA0lwKekxevWy6uG1f7vis8V1J+joYn317vKRhbd8bHGxfuaj362s7S+u2TwfUf4RmnD2GZW1L31zanHdz9yzolg/d1K9Y7mqX/c+l/dz5675w2J9xuCP62y797BnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGGcfoyichbonmjsdcteB8rTI/3PBpGJ99+VzK2tnztreUE8HvbbnyGL9ilOfLtavece9lbWBN8v/rnmT651gWz5+oeQ/95S/94y/K/+fxt7D7xJr7NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAmmbB6jCcceW1nb/eAJxXW/es5Xi/VpfeVx9okuX2p6fzR+wee9MVSsT3bvHooxVOds/YvWX1lZm3pNed2hzVsaaanrmpqyGcD4QNiBJAg7kARhB5Ig7EAShB1IgrADSfTuIGqPObBrV2Vt8vzqmiQtmXZ5sb7x5tOK9fnnP1Os/+i1kyprL7x8YnHdvknl8ebLzl5frC89uTzlczvNfmxJsX72DdVTQg/tqHfN+fGn7p7d9nLbg7Y3jFh2s+2Xba+rfV3a3jYBNGssb+O/IumSUZbfFhFzal+PtLYtAK1WN+wR8biknR3oBUAbNfMB3bW219fe5h9f9STbS2wP2B7Yp8Pvul3AeNFo2O+UdIakOZK2S/pc1RMjYllE9EdE/0SVJzAE0D4NhT0idkTE/og4IOkuSdWXNwXQExoKu+3pIx5+QNKGqucC6A11z2e3/YCkiySdKGmHpE/VHs+RFJK2SPpoRNS9QPnhfD57Vtseml2sr5tbPle/ZMvQL4r1hV/4i2J9xue/V6zHUPlc/fGodD573YNqImLRKIvvbrorAB3F4bJAEoQdSIKwA0kQdiAJwg4kwSmuyf3k799drD/9W7fV+Q7laZdLPri0PLT2q3c8Wax37iLo4wN7diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2cW7bJ367WP/2h5YW60f56Ka2f/vPzqysnfzldcV1G5+IGqNhzw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDOPg7sm99fWfvmteVx9F87orlx9BfrXA565SerLx0++Rdrm9o2Dg17diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2cWDL7/VV1k5rchx9+/7yOPofXX9DsX70t9Y0tX20Tt09u+2Zth+zvdH2s7avqy2fanuV7U212+Pb3y6ARo3lbfyQpBsi4p2SLpR0je3Zkm6UtDoiZklaXXsMoEfVDXtEbI+Ip2v3d0naKGmGpAWSVtSetkLSwjb1CKAFDukDOtunSXqXpDWSpkXEdmn4F4KkkyrWWWJ7wPbAPu1tsl0AjRpz2G0fI+lBSddHxOtjXS8ilkVEf0T0T9TkRnoE0AJjCrvtiRoO+n0R8Y3a4h22p9fq0yUNtqdFAK1Qd+jNtiXdLWljRNw6orRS0mJJt9RuH25Lh1DfCVOL9e9f/vlCtbl3Uxc9cW2xfsZDDK0dLsYyzj5P0oclPWN7XW3ZTRoO+ddtXyXpRUlXtKVDAC1RN+wR8YQkV5Srr0wAoKdwuCyQBGEHkiDsQBKEHUiCsANJcIprD+g7vnzC4PVrvlOsH+PGx9L/8X/fWazPunpTsc60yocP9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7D3glcvOKdbnH/1Ysb4/Gt/2I5++qFif8gbnq48X7NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2XvA73/8X4v1/dH4WeNn/vOfFOtnPcg4ehbs2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgibHMzz5T0j2STtbwZcKXRcTttm+WdLWkn9aeelNEPNKuRsez8456sVjvc/l38nf37K+szV46WFx3qFjFeDKWg2qGJN0QEU/bPlbSU7ZX1Wq3RcRn29cegFYZy/zs2yVtr93fZXujpBntbgxAax3S3+y2T5P0LkkHj7G81vZ628ttjzqHke0ltgdsD+zT3ua6BdCwMYfd9jGSHpR0fUS8LulOSWdImqPhPf/nRlsvIpZFRH9E9E9U43OSAWjOmMJue6KGg35fRHxDkiJiR0Tsj4gDku6SNLd9bQJoVt2w27akuyVtjIhbRyyfPuJpH5C0ofXtAWiVsXwaP0/ShyU9Y3tdbdlNkhbZniMpJG2R9NE29JfC9fddVaw/d/UXi/U/Xv6nlbWZm59sqCeMP2P5NP4JSR6lxJg6cBjhCDogCcIOJEHYgSQIO5AEYQeSIOxAEo5oYr7fQ3Scp8YFvrhj2wOyWROr9XrsHG2onD07kAVhB5Ig7EAShB1IgrADSRB2IAnCDiTR0XF22z+V9MKIRSdKeqVjDRyaXu2tV/uS6K1Rrezt1Ij4ldEKHQ372zZuD0REf9caKOjV3nq1L4neGtWp3ngbDyRB2IEkuh32ZV3efkmv9tarfUn01qiO9NbVv9kBdE639+wAOoSwA0l0Jey2L7H937aft31jN3qoYnuL7Wdsr7M90OVeltsetL1hxLKptlfZ3lS7HXWOvS71drPtl2uv3Trbl3apt5m2H7O90faztq+rLe/qa1foqyOvW8f/ZrfdJ+lHkt4naauktZIWRcQPO9pIBdtbJPVHRNcPwLD9O5J+LumeiPiN2rKlknZGxC21X5THR8Qne6S3myX9vNvTeNdmK5o+cppxSQslfURdfO0Kff2BOvC6dWPPPlfS8xGxOSLelPQ1SQu60EfPi4jHJe18y+IFklbU7q/Q8A9Lx1X01hMiYntEPF27v0vSwWnGu/raFfrqiG6EfYakl0Y83qremu89JD1q+ynbS7rdzCimRcR2afiHR9JJXe7nrepO491Jb5lmvGdeu0amP29WN8I+2vWxemn8b15E/Kak90u6pvZ2FWMzpmm8O2WUacZ7QqPTnzerG2HfKmnmiMenSNrWhT5GFRHbareDkh5S701FvePgDLq128Eu9/P/emka79GmGVcPvHbdnP68G2FfK2mW7dNtT5J0paSVXejjbWxPqX1wIttTJM1X701FvVLS4tr9xZIe7mIvv6RXpvGummZcXX7tuj79eUR0/EvSpRr+RP7Hkv6qGz1U9PXrkn5Q+3q2271JekDDb+v2afgd0VWSTpC0WtKm2u3UHurtXknPSFqv4WBN71Jv79Hwn4brJa2rfV3a7deu0FdHXjcOlwWS4Ag6IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUji/wDkMGWeo8W1dAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[9].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.to_categorical(y_train, num_classes=None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=None)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 20:05:23.648907: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 14s 28ms/step - loss: 0.2455 - accuracy: 0.9251 - val_loss: 0.1326 - val_accuracy: 0.9584\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 17s 35ms/step - loss: 0.1004 - accuracy: 0.9693 - val_loss: 0.0883 - val_accuracy: 0.9731\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 18s 39ms/step - loss: 0.0748 - accuracy: 0.9776 - val_loss: 0.0691 - val_accuracy: 0.9802\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0610 - accuracy: 0.9823 - val_loss: 0.0762 - val_accuracy: 0.9793\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0494 - accuracy: 0.9847 - val_loss: 0.0839 - val_accuracy: 0.9769\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 13s 29ms/step - loss: 0.0434 - accuracy: 0.9870 - val_loss: 0.0789 - val_accuracy: 0.9791\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 0.0376 - accuracy: 0.9885 - val_loss: 0.0778 - val_accuracy: 0.9827\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0339 - accuracy: 0.9900 - val_loss: 0.0850 - val_accuracy: 0.9808\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 13s 29ms/step - loss: 0.0319 - accuracy: 0.9913 - val_loss: 0.0900 - val_accuracy: 0.9798\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 19s 41ms/step - loss: 0.0274 - accuracy: 0.9918 - val_loss: 0.0865 - val_accuracy: 0.9818\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 0.0273 - accuracy: 0.9922 - val_loss: 0.0885 - val_accuracy: 0.9828\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 21s 45ms/step - loss: 0.0241 - accuracy: 0.9930 - val_loss: 0.1042 - val_accuracy: 0.9822\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.0226 - accuracy: 0.9935 - val_loss: 0.1176 - val_accuracy: 0.9820\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 18s 39ms/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 0.1018 - val_accuracy: 0.9824\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 15s 31ms/step - loss: 0.0202 - accuracy: 0.9943 - val_loss: 0.1108 - val_accuracy: 0.9823\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 15s 31ms/step - loss: 0.0197 - accuracy: 0.9945 - val_loss: 0.1067 - val_accuracy: 0.9825\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.1203 - val_accuracy: 0.9819\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 13s 29ms/step - loss: 0.0199 - accuracy: 0.9948 - val_loss: 0.1179 - val_accuracy: 0.9830\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0172 - accuracy: 0.9952 - val_loss: 0.1296 - val_accuracy: 0.9822\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0184 - accuracy: 0.9952 - val_loss: 0.1298 - val_accuracy: 0.9826\n",
      "Test loss: 0.12977002561092377\n",
      "Test accuracy: 0.9825999736785889\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv Net\n",
    "Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "469/469 [==============================] - 74s 157ms/step - loss: 2.2828 - accuracy: 0.1403 - val_loss: 2.2433 - val_accuracy: 0.3244\n",
      "Epoch 2/12\n",
      "469/469 [==============================] - 82s 175ms/step - loss: 2.2216 - accuracy: 0.2460 - val_loss: 2.1683 - val_accuracy: 0.5670\n",
      "Epoch 3/12\n",
      "469/469 [==============================] - 73s 155ms/step - loss: 2.1451 - accuracy: 0.3597 - val_loss: 2.0708 - val_accuracy: 0.6704\n",
      "Epoch 4/12\n",
      "469/469 [==============================] - 71s 151ms/step - loss: 2.0433 - accuracy: 0.4493 - val_loss: 1.9426 - val_accuracy: 0.7221\n",
      "Epoch 5/12\n",
      "469/469 [==============================] - 74s 158ms/step - loss: 1.9149 - accuracy: 0.5145 - val_loss: 1.7797 - val_accuracy: 0.7536\n",
      "Epoch 6/12\n",
      "469/469 [==============================] - 162s 345ms/step - loss: 1.7605 - accuracy: 0.5595 - val_loss: 1.5879 - val_accuracy: 0.7761\n",
      "Epoch 7/12\n",
      "469/469 [==============================] - 89s 188ms/step - loss: 1.5888 - accuracy: 0.6035 - val_loss: 1.3843 - val_accuracy: 0.7947\n",
      "Epoch 8/12\n",
      "469/469 [==============================] - 87s 186ms/step - loss: 1.4244 - accuracy: 0.6351 - val_loss: 1.1926 - val_accuracy: 0.8099\n",
      "Epoch 9/12\n",
      "469/469 [==============================] - 81s 172ms/step - loss: 1.2748 - accuracy: 0.6633 - val_loss: 1.0308 - val_accuracy: 0.8203\n",
      "Epoch 10/12\n",
      "469/469 [==============================] - 76s 163ms/step - loss: 1.1579 - accuracy: 0.6811 - val_loss: 0.9032 - val_accuracy: 0.8303\n",
      "Epoch 11/12\n",
      "469/469 [==============================] - 76s 162ms/step - loss: 1.0575 - accuracy: 0.7021 - val_loss: 0.8038 - val_accuracy: 0.8372\n",
      "Epoch 12/12\n",
      "469/469 [==============================] - 80s 170ms/step - loss: 0.9767 - accuracy: 0.7205 - val_loss: 0.7264 - val_accuracy: 0.8448\n",
      "Test loss: 0.7264227867126465\n",
      "Test accuracy: 0.8447999954223633\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.7264227867126465\n",
      "Test accuracy: 0.8447999954223633\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd9381655b0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAANh0lEQVR4nO3df6zddX3H8dfL/sJeYFKwtSuVKqKxOsHlCppuSw3DAYYUo2w0GekSZskGCSxmG2ExkmxxjIiETWdSR2clCFOBQLRzksaNkLHKhZRSKFuRdVh71wvUrUXgtqXv/XG/LJdyz+dezvd7zve07+cjuTnnfN/ne77vfHtf/X7v+XzP+TgiBODY95a2GwDQH4QdSIKwA0kQdiAJwg4kMbufG5vreXGchvq5SSCVV/QLHYhxT1WrFXbb50u6RdIsSX8XETeUnn+chnSOz62zSQAFm2NTx1rXp/G2Z0n6qqQLJC2XtNr28m5fD0Bv1fmb/WxJT0fEMxFxQNKdklY10xaAptUJ+xJJP530eFe17HVsr7U9YnvkoMZrbA5AHXXCPtWbAG+49jYi1kXEcEQMz9G8GpsDUEedsO+StHTS41Ml7a7XDoBeqRP2hyWdYftdtudKulTSfc20BaBpXQ+9RcQh21dJ+idNDL2tj4gnGusMQKNqjbNHxEZJGxvqBUAPcbkskARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IIlaUzbb3ilpv6RXJR2KiOEmmgLQvFphr3w8Ip5v4HUA9BCn8UASdcMekn5o+xHba6d6gu21tkdsjxzUeM3NAehW3dP4FRGx2/ZCSffbfioiHpj8hIhYJ2mdJJ3oBVFzewC6VOvIHhG7q9sxSfdIOruJpgA0r+uw2x6yfcJr9yV9QtK2phoD0Kw6p/GLJN1j+7XX+VZE/KCRrgA0ruuwR8Qzks5ssBcAPcTQG5AEYQeSIOxAEoQdSIKwA0k08UGYFF747Mc61t552dPFdZ8aW1SsHxifU6wvuaNcn7/rxY61w1ueLK6LPDiyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLPP0J/88bc61j499PPyyqfX3PjKcnnnoZc61m557uM1N370+vHYaR1rQzf9UnHd2Zseabqd1nFkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkHNG/SVpO9II4x+f2bXtN+sVnzulYe/5D5f8zT9pe3sc/f7+L9bkf+p9i/cYP3t2xdt5bXy6u+/2Xji/WPzm/82fl63o5DhTrm8eHivWVxx3setvv+f4Vxfp71z7c9Wu3aXNs0r7YO+UvFEd2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCz7PP0NB3Nxdq9V77xHqr62/esbJj7S9WLCtv+1/K33l/48r3dNHRzMx++XCxPrR1tFg/+YG7ivVfmdv5+/bn7yx/F/+xaNoju+31tsdsb5u0bIHt+23vqG5P6m2bAOqayWn8NySdf8SyayVtiogzJG2qHgMYYNOGPSIekLT3iMWrJG2o7m+QdHGzbQFoWrdv0C2KiFFJqm4Xdnqi7bW2R2yPHNR4l5sDUFfP342PiHURMRwRw3M0r9ebA9BBt2HfY3uxJFW3Y821BKAXug37fZLWVPfXSLq3mXYA9Mq04+y279DEN5efYnuXpC9IukHSt21fLulZSZf0skmUHfrvPR1rQ3d1rknSq9O89tB3X+iio2bs+f2PFesfmFv+9f3S3vd1rC37+2eK6x4qVo9O04Y9IlZ3KB2d30IBJMXlskAShB1IgrADSRB2IAnCDiTBR1zRmtmnLS3Wv3LdV4r1OZ5VrH/nlt/sWDt59KHiuscijuxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7GjNU3+0pFj/yLzyVNZPHChPR73gyZfedE/HMo7sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+zoqfFPfqRj7dHP3DzN2uUZhP7g6quL9bf+64+nef1cOLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs6Onnr2g8/HkeJfH0Vf/53nF+vwfPFasR7Gaz7RHdtvrbY/Z3jZp2fW2f2Z7S/VzYW/bBFDXTE7jvyHp/CmW3xwRZ1U/G5ttC0DTpg17RDwgaW8fegHQQ3XeoLvK9tbqNP+kTk+yvdb2iO2RgxqvsTkAdXQb9q9JOl3SWZJGJd3U6YkRsS4ihiNieM40H2wA0DtdhT0i9kTEqxFxWNLXJZ3dbFsAmtZV2G0vnvTwU5K2dXougMEw7Ti77TskrZR0iu1dkr4gaaXtszQxlLlT0hW9axGD7C0nnFCsX/brD3as7Tv8SnHdsS++u1ifN/5wsY7XmzbsEbF6isW39qAXAD3E5bJAEoQdSIKwA0kQdiAJwg4kwUdcUcuO6z9QrH/vlL/tWFu149PFdedtZGitSRzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtlR9L+/+9Fifevv/HWx/pNDBzvWXvyrU4vrztNosY43hyM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOHtys5f8crF+zef/oVif5/Kv0KWPXdax9vZ/5PPq/cSRHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJz9GOfZ5X/iM7+3q1i/5PgXivXb9y8s1hd9vvPx5HBxTTRt2iO77aW2f2R7u+0nbF9dLV9g+37bO6rbk3rfLoBuzeQ0/pCkz0XE+yV9VNKVtpdLulbSpog4Q9Km6jGAATVt2CNiNCIere7vl7Rd0hJJqyRtqJ62QdLFPeoRQAPe1Bt0tpdJ+rCkzZIWRcSoNPEfgqQp/3izvdb2iO2Rgxqv2S6Abs047LaPl3SXpGsiYt9M14uIdRExHBHDczSvmx4BNGBGYbc9RxNBvz0i7q4W77G9uKovljTWmxYBNGHaoTfblnSrpO0R8eVJpfskrZF0Q3V7b086RD1nvq9Y/vOFt9V6+a9+8ZJi/W2PPVTr9dGcmYyzr5B0maTHbW+pll2niZB/2/blkp6VVP5XB9CqacMeEQ9Kcofyuc22A6BXuFwWSIKwA0kQdiAJwg4kQdiBJPiI6zFg1vL3dqytvbPe5Q/L119ZrC+77d9qvT76hyM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOPsx4Kk/7PzFvhfNn/GXCk3p1H8+UH5CRK3XR/9wZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnPwq8ctHZxfqmi24qVOc32wyOWhzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJmczPvlTSNyW9Q9JhSesi4hbb10v6rKTnqqdeFxEbe9VoZrtXzCrW3zm7+7H02/cvLNbn7Ct/np1Psx89ZnJRzSFJn4uIR22fIOkR2/dXtZsj4ku9aw9AU2YyP/uopNHq/n7b2yUt6XVjAJr1pv5mt71M0oclba4WXWV7q+31tqf8biTba22P2B45qPF63QLo2ozDbvt4SXdJuiYi9kn6mqTTJZ2liSP/lBdoR8S6iBiOiOE5mle/YwBdmVHYbc/RRNBvj4i7JSki9kTEqxFxWNLXJZU/rQGgVdOG3bYl3Sppe0R8edLyxZOe9ilJ25pvD0BTZvJu/ApJl0l63PaWatl1klbbPksToy87JV3Rg/5Q01++sLxYf+i3lhXrMfp4g92gTTN5N/5BSZ6ixJg6cBThCjogCcIOJEHYgSQIO5AEYQeSIOxAEo4+Trl7ohfEOT63b9sDstkcm7Qv9k41VM6RHciCsANJEHYgCcIOJEHYgSQIO5AEYQeS6Os4u+3nJP3XpEWnSHq+bw28OYPa26D2JdFbt5rs7bSIePtUhb6G/Q0bt0ciYri1BgoGtbdB7Uuit271qzdO44EkCDuQRNthX9fy9ksGtbdB7Uuit271pbdW/2YH0D9tH9kB9AlhB5JoJey2z7f977aftn1tGz10Ynun7cdtb7E90nIv622P2d42adkC2/fb3lHdTjnHXku9XW/7Z9W+22L7wpZ6W2r7R7a3237C9tXV8lb3XaGvvuy3vv/NbnuWpP+QdJ6kXZIelrQ6Ip7sayMd2N4paTgiWr8Aw/ZvSHpR0jcj4oPVshsl7Y2IG6r/KE+KiD8dkN6ul/Ri29N4V7MVLZ48zbikiyX9nlrcd4W+flt92G9tHNnPlvR0RDwTEQck3SlpVQt9DLyIeEDS3iMWr5K0obq/QRO/LH3XobeBEBGjEfFodX+/pNemGW913xX66os2wr5E0k8nPd6lwZrvPST90PYjtte23cwUFkXEqDTxyyNpYcv9HGnaabz76Yhpxgdm33Uz/XldbYR9qu/HGqTxvxUR8auSLpB0ZXW6ipmZ0TTe/TLFNOMDodvpz+tqI+y7JC2d9PhUSbtb6GNKEbG7uh2TdI8GbyrqPa/NoFvdjrXcz/8bpGm8p5pmXAOw79qc/ryNsD8s6Qzb77I9V9Klku5roY83sD1UvXEi20OSPqHBm4r6PklrqvtrJN3bYi+vMyjTeHeaZlwt77vWpz+PiL7/SLpQE+/I/0TSn7XRQ4e+3i3psernibZ7k3SHJk7rDmrijOhySSdL2iRpR3W7YIB6u03S45K2aiJYi1vq7dc08afhVklbqp8L2953hb76st+4XBZIgivogCQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJ/wNGNvRI2D7VDgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  8.03459201e-08,   1.38438466e-07,   4.18382228e-07,\n",
       "           3.68611836e-06,   3.55962615e-09,   2.90193564e-10,\n",
       "           2.80381187e-12,   9.99995351e-01,   1.96343386e-08,\n",
       "           3.15586846e-07]], dtype=float32),\n",
       " array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.]]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test[0:1]), y_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([7]), array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.]]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(x_test[0:1]), y_test[:1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
